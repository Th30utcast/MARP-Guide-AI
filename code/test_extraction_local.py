"""
Local test script for DocumentExtracted event using your actual code.
This simulates DocumentDiscovered events from test-pdfs/ and tests extraction.
"""

import json
import time
import threading
import logging
import sys
import os
from pathlib import Path
from datetime import datetime, timezone
import uuid

# Add src directory to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.extraction.event_broker import RabbitMQEventBroker
from src.extraction.extraction_service import ExtractionService

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

TEST_PDFS_DIR = "test-pdfs"

#!! Delete this once tino makes the DocumentDiscovered event
def create_document_discovered_event(file_path: str, title: str) -> dict:
    """Create a DocumentDiscovered event from a test PDF."""
    return {
        "eventType": "DocumentDiscovered",
        "eventId": str(uuid.uuid4()),
        "timestamp": datetime.now(timezone.utc).isoformat().replace("+00:00", "Z"),
        "correlationId": str(uuid.uuid4()),
        "source": "test-script",
        "version": "1.0",
        "payload": {
            "documentId": f"test-{Path(file_path).stem}",
            "title": title,
            "url": str(Path(file_path).absolute()),
            "discoveredAt": datetime.now(timezone.utc).isoformat().replace("+00:00", "Z"),
            "fileSize": Path(file_path).stat().st_size
        }
    }


def consume_extracted_events(broker, extraction_service):
    """Consume and print DocumentExtracted events."""
    
    def callback(ch, method, properties, body):
        try:
            event = json.loads(body)
            logger.info("=" * 80)
            logger.info("‚úÖ RECEIVED DOCUMENTEXTRACTED EVENT:")
            logger.info("=" * 80)
            logger.info(json.dumps(event, indent=2))
            logger.info("=" * 80)
            ch.basic_ack(delivery_tag=method.delivery_tag)
        except Exception as e:
            logger.error(f"Error processing extracted event: {str(e)}")
            ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
    
    logger.info("üîç Listening for DocumentExtracted events...")
    broker.consume(
        queue_name="documents.extracted",
        callback=callback,
        auto_ack=False
    )


def main():
    logger.info("üöÄ Starting local extraction test...")
    
    # Initialize broker
    try:
        broker = RabbitMQEventBroker(
            host="localhost",
            port=5672,
            username="guest",
            password="guest"
        )
        logger.info("‚úÖ Connected to RabbitMQ")
    except Exception as e:
        logger.error(f"‚ùå Failed to connect to RabbitMQ: {str(e)}")
        logger.info("üí° Make sure RabbitMQ is running: docker-compose up -d")
        return
    
    # Declare queues
    broker.declare_queue("documents.discovered")
    broker.declare_queue("documents.extracted")
    
    # Declare exchange
    if broker.channel:
        broker.channel.exchange_declare(exchange="events", exchange_type="topic", durable=True)
        broker.channel.queue_bind(
            exchange="events",
            queue="documents.discovered",
            routing_key="documents.discovered"
        )
        broker.channel.queue_bind(
            exchange="events",
            queue="documents.extracted",
            routing_key="documents.extracted"
        )
    
    # Initialize extraction service
    extraction_service = ExtractionService(event_broker=broker)
    logger.info("‚úÖ Extraction service initialized")
    
    # Start consumer thread for extracted events
    consumer_thread = threading.Thread(
        target=consume_extracted_events,
        args=(broker, extraction_service),
        daemon=True
    )
    consumer_thread.start()
    
    # Give consumer time to start
    time.sleep(1)
    
    # Find and process test PDFs
    pdf_files = list(Path(TEST_PDFS_DIR).glob("*.pdf"))
    
    if not pdf_files:
        logger.error(f"‚ùå No PDFs found in {TEST_PDFS_DIR}")
        broker.close()
        return
    
    logger.info(f"üìÑ Found {len(pdf_files)} PDF(s) to test:\n")
    
    for pdf_path in pdf_files:
        try:
            logger.info(f"Processing: {pdf_path.name}")
            
            # Create simulated DocumentDiscovered event
            discovered_event = create_document_discovered_event(
                str(pdf_path),
                pdf_path.stem
            )
            
            logger.info(f"üì§ Publishing DocumentDiscovered event for: {pdf_path.name}")
            
            # Publish to queue
            broker.publish(
                routing_key="documents.discovered",
                message=json.dumps(discovered_event),
                exchange="events"
            )
            
            # Wait a moment for processing
            time.sleep(2)
            
        except Exception as e:
            logger.error(f"Error processing {pdf_path.name}: {str(e)}")
    
    logger.info("\n‚úÖ All PDFs published. Listening for results (Ctrl+C to exit)...")
    
    try:
        # Keep the consumer thread alive
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        logger.info("\n‚èπÔ∏è Stopping test...")
        broker.close()


if __name__ == "__main__":
    main()